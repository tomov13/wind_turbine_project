{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c0659b1-2109-4fdb-9d86-4988b49917d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"/Users/ovidiumtoma@gmail.com/wind_turbine_project/src/wt_ingestion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbac7217-a7b8-4c5a-96fb-2b99d1274124",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-21 22:35:44 - INFO - RawDataIngestor initialized.\n2025-02-21 22:35:44 - INFO - Loading original turbine data from dbfs:/FileStore/tables\n2025-02-21 22:35:46 - INFO - Successfully loaded 11160 original turbine dataset records.\n2025-02-21 22:35:46 - INFO - Writing data to Delta table: bronze_data.original_turbine_bronze\n2025-02-21 22:35:51 - INFO - Successfully written data to bronze_data.original_turbine_bronze\n2025-02-21 22:35:51 - INFO - Loading new turbine data from dbfs:/FileStore/tables\n2025-02-21 22:35:54 - INFO - Successfully loaded 175200 new turbine dataset records.\n2025-02-21 22:35:54 - INFO - Maximum ID number from original dataset: 15\n2025-02-21 22:35:54 - INFO - Successfully added turbine_id to new turbine dataset records.\n2025-02-21 22:35:54 - INFO - Writing data to Delta table: bronze_data.new_turbine_bronze\n2025-02-21 22:36:02 - INFO - Successfully written data to bronze_data.new_turbine_bronze\nIngestion process completed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize and trigger the ingestion class\n",
    "ingestor = RawDataIngestor(spark)\n",
    "\n",
    "# Define directory path where CSVs are stored\n",
    "raw_directory_path = \"dbfs:/FileStore/tables\"\n",
    "\n",
    "# Load both datasets into Bronze tables\n",
    "df_original_turbine_data = ingestor.load_original_turbine_data(raw_directory_path)\n",
    "ingestor.write_bronze(df_original_turbine_data, \"original_turbine_bronze\")\n",
    "\n",
    "df_new_turbine_data = ingestor.load_new_turbine_data(raw_directory_path)\n",
    "ingestor.write_bronze(df_new_turbine_data, \"new_turbine_bronze\")\n",
    "\n",
    "print(\"Ingestion process completed.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3182424124548748,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "1_bronze_ingestion",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
